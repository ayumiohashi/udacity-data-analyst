{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists. \n",
    "\n",
    "For this project, I will be working to understand the results of an A/B test run by an e-commerce website.  My goal is to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayumi\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset and take a look at the top few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and display the first 5 rows.\n",
    "df = pd.read_csv('data/ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the total number of rows.\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of unique users\n",
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the proportion of users converted\n",
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The number of times the `new_page` and `treatment` don't line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(landing_page==\"new_page\" & group==\"control\") | (landing_page==\"old_page\" & group==\"treatment\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a string to find the number of rows with \n",
    "#   landing_page : new page, group : control\n",
    "#   landing_page : old page, group : treatment\n",
    "\n",
    "query_string = '(landing_page==\"new_page\" & group==\"control\")'\n",
    "query_string += ' | '\n",
    "query_string += '(landing_page==\"old_page\" & group==\"treatment\")' \n",
    "\n",
    "query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of rows where new_page and treatment don't line up.\n",
    "df.query(query_string).user_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find if there is any row missing values.\n",
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rows where treatment is not aligned with new_page or control is not aligned with old_page, we cannot be sure if this row truly received the new or old page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string to filter out rows that do not align with correct test settings.\n",
    "# The rows will be kept if \n",
    "#   landing_page : new page, group : control\n",
    "#   landing_page : old page, group : treatment\n",
    "\n",
    "query_string = '(landing_page==\"new_page\" & group==\"treatment\")'\n",
    "query_string += ' | '\n",
    "query_string += '(landing_page==\"old_page\" & group==\"control\")' \n",
    "\n",
    "# Create new dataframe df2 with rows with correst test settings.\n",
    "df2 = df.query(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique user_ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of unique users in df2\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is one duplicated user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the duplicated user_id in df2\n",
    "df2_duplicated = df2[df2['user_id'].duplicated()==True]\n",
    "\n",
    "# Make sure there is only one duplicated user_id \n",
    "df2_duplicated.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                 2893\n",
       "user_id                             773192\n",
       "timestamp       2017-01-14 02:55:59.590927\n",
       "group                            treatment\n",
       "landing_page                      new_page\n",
       "converted                                0\n",
       "Name: 2862, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information for duplicated user_id \n",
    "df2_duplicated.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicated user_id in df2\n",
    "df2_duplicated.iloc[0]['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the row information for the repeat user_id? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2862"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the index of duplicated user_id in df2\n",
    "df2_duplicated_index = df2_duplicated.index.get_values()[0]\n",
    "df2_duplicated_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove one of the rows with a duplicate user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290585"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in df2\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the row of duplicated user_id by index\n",
    "df2 = df2.drop(df.index[df2_duplicated_index])\n",
    "\n",
    "# Make sure there is only one row dropped\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure there is no more duplicate user_id\n",
    "df2['user_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find conversion probability\n",
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find conversion probability for control group\n",
    "df2.query('group==\"control\"').converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find conversion probability for treatment group\n",
    "df2.query('group==\"treatment\"').converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find probability for displaying new page\n",
    "# Can be found by:\n",
    "#     Number of new page displayed / Total number of tests\n",
    "df2.query('landing_page==\"new_page\"').user_id.count()/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe there is no strong evidence to tell whether old or new page leads to more conversions.  The conversion rate for the old page is slightly better than the new page, but not by much.  The difference is only 0.00158 (0.12039 - 0.11881)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Define null hypothesis and alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null Hypothesis - The conversion rate of new pages is less or equal to the conversion rate of old pages.**\n",
    "$$ H_0: P_{new} \\leq P_{old} $$\n",
    "<br/><br/>\n",
    "\n",
    "**Alternative Hypothesis: - The conversion rate of new pages is greater to the conversion rate of old pages at a Type I error rate of 5%.**\n",
    "$$ H_1: P_{new} > P_{old} $$ <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the converted success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the converted rate in ab_data.csv regardless of the page. \n",
    "\n",
    "Use a sample size for each page equal to the ones in ab_data.csv.\n",
    "\n",
    "Perform the sampling distribution for the difference in converted between the two pages over 10,000 iterations of calculating an estimate from the null.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the convert rate for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From question above \"assume they are equal to the converted rate \n",
    "# in ab_data.csv regardless of the page.\"\n",
    "# Find the conversion rate of all data\n",
    "p_new = df2['converted'].mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the convert rate for $p_{old}$ under the null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The conversion rate for Pold is the same as Pnew.\n",
    "# See above comment.\n",
    "p_old = p_new\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is $n_{new}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find new_page counts in data\n",
    "n_new = df2.query('landing_page==\"new_page\"').user_id.count()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is $n_{old}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find old_page counts in data\n",
    "n_old = df2.query('landing_page==\"old_page\"').user_id.count()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating n_new transaction with a convert rate of p_new with 0's and 1's\n",
    "new_page_converted = np.random.binomial(1, p_new, n_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating p_old transaction with a convert rate of p_old with 0's and 1's\n",
    "old_page_converted = np.random.binomial(1, p_old, n_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00041486373841166657"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the difference in conversion rate between 2 two pages\n",
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate 10,000 $p_{new}$ - $p_{old}$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = []\n",
    "\n",
    "# Perform the sampling distribution for the difference in conversion rate\n",
    "# between the two pages over 10,000 trails.\n",
    "new_converted_simulation = np.random.binomial(n_new, p_new,  10000)/n_new\n",
    "old_converted_simulation = np.random.binomial(n_old, p_old,  10000)/n_old\n",
    "p_diffs = new_converted_simulation - old_converted_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "p_diffs = np.array(p_diffs)\n",
    "p_diffs.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the p_diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1e1edbd40f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution\n",
    "plt.hist(p_diffs)\n",
    "\n",
    "# Calculate observed difference\n",
    "obs_diff = df2.query('group==\"treatment\"').converted.mean() - df2.query('group==\"control\"').converted.mean()\n",
    "\n",
    "# Plot line for observed difference\n",
    "plt.axvline(obs_diff, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of the p_diffs are greater than the actual difference observed in ab_data.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the p-value by finding the proportion of values in the null \n",
    "# distribution that were greater than our observed difference.\n",
    "(p_diffs > obs_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value computed in part j is called \"p-value\" in scientific studies. The p-value is the probability of getting our statistic (or a more extreme value) if the null is true. When the p-value is large, which in this case, we have evidence that our statistic was likely to come from the null hypothesis. Therefore, we do not have evidence to reject the null.\n",
    "\n",
    "Also the p-value is greater than Type I Error (p-value 0.9062 > alpha 0.05), thus we fail to reject the null.\n",
    "\n",
    "This means that the conversion rate of new pages are slightly less than the conversion rate of old pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stasmodels api\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Number of sucesses in trials for old and new pages\n",
    "convert_old = df2.query(\"landing_page == 'old_page' and converted == 1\").shape[0]\n",
    "convert_new = df2.query(\"landing_page == 'new_page' and converted == 1\").shape[0]\n",
    "\n",
    "# Number of trials for old and new pages\n",
    "n_old = df2.shape[0] - df2.query(\"landing_page == 'new_page'\").shape[0]\n",
    "n_new = df2.query(\"landing_page == 'new_page'\").shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use stats.proportions_ztest to compute the test statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.311\n",
      "0.905\n"
     ]
    }
   ],
   "source": [
    "# Calculating z_score and p_value using stats.proportions_ztest()\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_old, convert_new], [n_old, n_new], alternative='smaller')\n",
    "print('{0:0.3f}'.format(z_score))\n",
    "print('{0:0.3f}'.format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-score is our deviation from the mean in units of standard deviation. It cannot to be used to tell explicitly whether we accept or reject our null hypothesis.\n",
    "\n",
    "The p-value is the probability of getting our statistic (or a more extreme value) if the null is true. When the p-value is large, which in this case, we have evidence that our statistic was likely to come from the null hypothesis. Therefore, we do not have evidence to reject the null.\n",
    "\n",
    "Also the p-value is greater than Type I Error (p-value 0.905 > alpha 0.05), thus we fail to reject the null. \n",
    "\n",
    "I got the p-value of 0.9062 from sampling distributions (question 2.j) which matches closely to the p-value 0.905 I got from proportions_ztest (question 2.m). The finding from previous question that we fail to reject the null agrees with question 2.k also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "The result I acheived in the previous A/B test can also be acheived by performing regression.\n",
    "\n",
    "I will be peforming Logistic Regression since I am predicting 0 (no conversion) or 1 (conversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>control</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  user_id                   timestamp      group landing_page  \\\n",
       "0      0   851104  2017-01-21 22:11:48.556739    control     old_page   \n",
       "1      1   804228  2017-01-12 08:01:45.159739    control     old_page   \n",
       "2      2   661590  2017-01-11 16:55:06.154213  treatment     new_page   \n",
       "3      3   853541  2017-01-08 18:28:03.143765  treatment     new_page   \n",
       "4      4   864975  2017-01-21 01:52:26.210827    control     old_page   \n",
       "\n",
       "   converted  intercept  control  treatment  \n",
       "0          0          1        1          0  \n",
       "1          0          1        1          0  \n",
       "2          0          1        0          1  \n",
       "3          0          1        0          1  \n",
       "4          1          1        1          0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an intercept column\n",
    "df2['intercept'] = 1\n",
    "\n",
    "# Create dummy variable columns for group\n",
    "df2[['control', 'treatment']] = pd.get_dummies(df2['group'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use statsmodels to import the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  user_id                   timestamp      group landing_page  \\\n",
       "0      0   851104  2017-01-21 22:11:48.556739    control     old_page   \n",
       "1      1   804228  2017-01-12 08:01:45.159739    control     old_page   \n",
       "2      2   661590  2017-01-11 16:55:06.154213  treatment     new_page   \n",
       "3      3   853541  2017-01-08 18:28:03.143765  treatment     new_page   \n",
       "4      4   864975  2017-01-21 01:52:26.210827    control     old_page   \n",
       "\n",
       "   converted  intercept  treatment  \n",
       "0          0          1          0  \n",
       "1          0          1          0  \n",
       "2          0          1          1  \n",
       "3          0          1          1  \n",
       "4          1          1          0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column 'control' as I am using it as baseline\n",
    "df2 = df2.drop('control', axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "log_mod = sm.Logit(df2['converted'], df2[['intercept', 'treatment']])\n",
    "\n",
    "# Fit the model\n",
    "results = log_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 28 Jun 2018</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:24:55</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment</th> <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Thu, 28 Jun 2018   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        15:24:55   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "treatment     -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Workaround the error \"module 'scipy.stats' has no attribute 'chisqprob'\"\n",
    "# https://github.com/statsmodels/statsmodels/issues/3931\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n",
    "# Display the summary\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative hypothesis for Logistic Regression is two-sided test where as it was one-sided test for Part II.  So here null and alternative hypotheses are:\n",
    "\n",
    "**Null Hypothesis - The conversion rate of new pages is equal to the conversion rate of old pages.**\n",
    "$$ H_0: P_{new} = P_{old} $$\n",
    "<br/>\n",
    "\n",
    "**Alternative Hypothesis: - The conversion rate of new pages is not equal to the conversion rate of old pages at a Type I error rate of 5%.**\n",
    "$$ H_1: P_{new} \\neq P_{old} $$ \n",
    "<br/>\n",
    "\n",
    "The p-value I got from Logistic Regression is 0.190 which doesn't match with p-value 0.9062 and 0.905 I got from the distribution sampling and proportions_ztest, respectively.  I would think this is expected as p-value for Logistic Regression is for two-sided test and the others were for one-sided test.\n",
    "\n",
    "\n",
    "**Knowing that Part iii is a two-tailed test and Part ii is a one-tail test, can I convert the p-values between each other?**\n",
    "\n",
    "According to the resource I found (below), \"Depending on the direction of the one-tailed hypothesis, its p-value is either 0.5\\*(two-tailed p-value) or 1-0.5\\*(two-tailed p-value) if the test statistic symmetrically distributed about zero.\"\n",
    "\n",
    "I can calculate one-tailed p-value from two-tailed p-value by<br/>\n",
    "0.5\\*0.190 = 0.095 or 1-(0.5\\*0.190) = 0.905 ---> Matches with proportions_ztest p-value.\n",
    "\n",
    "Or I can calculate two-tailed p-value from one-tailed p-value by<br/>\n",
    "0.095/0.5 = 0.19 or (1-0.905)/0.5 = 0.19 ---> Matches with Logistic Regression p-value.\n",
    "\n",
    "\n",
    "Resource: This is the [webpage](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/) I got information about how to covert p-value between one-tail and two-tailed tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why it is a good idea to consider other factors to add into your regression model?  Are there any disadvantages to adding additional terms into your regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other things that might influence whether or not an individual converts and might consider adding into the regression models are: \n",
    "* How long the experiement run?  Could the existing users bias results in short time frame?\n",
    "* Were they all new users or did the test include existing users?  The existing users might needed to adjust to the change.\n",
    "* Was the conversion rate alone not the best metric?  Was revenue needed to be accounted for?\n",
    "* Did the experiement have enough trafic to produce significant and repeatable results in this time frame?\n",
    "\n",
    "The disadvantage of adding additional terms into the regression model is that there might be a chance multicollinearity exists. We would like explanatory variables to be related to the response, but not to be related to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. Does it appear that country had an impact on conversion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load country info of users.\n",
    "df_country = pd.read_csv('data/countries.csv')\n",
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290584 entries, 0 to 290584\n",
      "Data columns (total 8 columns):\n",
      "index           290584 non-null int64\n",
      "user_id         290584 non-null int64\n",
      "timestamp       290584 non-null object\n",
      "group           290584 non-null object\n",
      "landing_page    290584 non-null object\n",
      "converted       290584 non-null int64\n",
      "intercept       290584 non-null int64\n",
      "treatment       290584 non-null uint8\n",
      "dtypes: int64(4), object(3), uint8(1)\n",
      "memory usage: 18.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check df2 info before joining country data\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290584 entries, 0 to 290584\n",
      "Data columns (total 9 columns):\n",
      "index           290584 non-null int64\n",
      "user_id         290584 non-null int64\n",
      "timestamp       290584 non-null object\n",
      "group           290584 non-null object\n",
      "landing_page    290584 non-null object\n",
      "converted       290584 non-null int64\n",
      "intercept       290584 non-null int64\n",
      "treatment       290584 non-null uint8\n",
      "country         290584 non-null object\n",
      "dtypes: int64(4), object(4), uint8(1)\n",
      "memory usage: 20.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge df2 and df_country by user_id\n",
    "df_combined = df2.join(df_country.set_index( ['user_id'], verify_integrity=True), on=['user_id'], how='left')\n",
    "\n",
    "# Make sure new df_combined looks ok, total rows, non-null, etc.\n",
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at an interaction between page and country to see if there significant effects on conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA', 'UK'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get avariable countries\n",
    "df_combined['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>treatment</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  user_id                   timestamp      group landing_page  \\\n",
       "0      0   851104  2017-01-21 22:11:48.556739    control     old_page   \n",
       "1      1   804228  2017-01-12 08:01:45.159739    control     old_page   \n",
       "2      2   661590  2017-01-11 16:55:06.154213  treatment     new_page   \n",
       "3      3   853541  2017-01-08 18:28:03.143765  treatment     new_page   \n",
       "4      4   864975  2017-01-21 01:52:26.210827    control     old_page   \n",
       "\n",
       "   converted  intercept  treatment country  CA  UK  US  \n",
       "0          0          1          0      US   0   0   1  \n",
       "1          0          1          0      US   0   0   1  \n",
       "2          0          1          1      US   0   0   1  \n",
       "3          0          1          1      US   0   0   1  \n",
       "4          1          1          0      US   0   0   1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an intercept column\n",
    "df_combined['intercept'] = 1\n",
    "\n",
    "# Create dummy variable columns for group\n",
    "df_combined[['CA', 'UK', 'US']] = pd.get_dummies(df_combined['country'])\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>treatment</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  user_id                   timestamp      group landing_page  \\\n",
       "0      0   851104  2017-01-21 22:11:48.556739    control     old_page   \n",
       "1      1   804228  2017-01-12 08:01:45.159739    control     old_page   \n",
       "2      2   661590  2017-01-11 16:55:06.154213  treatment     new_page   \n",
       "3      3   853541  2017-01-08 18:28:03.143765  treatment     new_page   \n",
       "4      4   864975  2017-01-21 01:52:26.210827    control     old_page   \n",
       "\n",
       "   converted  intercept  treatment country  CA  UK  \n",
       "0          0          1          0      US   0   0  \n",
       "1          0          1          0      US   0   0  \n",
       "2          0          1          1      US   0   0  \n",
       "3          0          1          1      US   0   0  \n",
       "4          1          1          0      US   0   0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column 'US' as I am using it as baseline\n",
    "df_combined = df_combined.drop('US', axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 28 Jun 2018</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:24:57</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment</th> <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 28 Jun 2018   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        15:24:57   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "treatment     -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "UK             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "log_mod = sm.Logit(df_combined['converted'], df_combined[['intercept', 'treatment', 'CA', 'UK']])\n",
    "\n",
    "# Fit the model\n",
    "results = log_mod.fit()\n",
    "\n",
    "# Display the summary\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9852104557227469, 0.9600211149716509, 1.0099491671175422)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponentiate coefficient of each explanatory variables to interpret the result\n",
    "(np.exp(-0.0149), np.exp(-0.0408), np.exp(0.0099))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0150115583846535, 1.0416437559600236)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the reciprocal as treatment and CA multiplicative changes are less than 1. \n",
    "(1/np.exp(-0.0149), 1/np.exp(-0.0408))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion happens 1.0150 times less likely for treatment than control holding all else constant.<br/>\n",
    "Conversion happens 1.0416 times less likey for users living in CA than US holding all else constant.<br/>\n",
    "Conversion happens 1.0099 times likey for users living in UK than US holding all else constant.\n",
    "\n",
    "None of explanatory variables' p-value suggest that they are statistically significant.\n",
    "\n",
    "With the result above, it appears that country had no impact on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "> From the result of sampling distributions, built-in function proportions_ztest,<br/>\n",
    "and logistic regression, there is no strong evidence that new page generate<br/>\n",
    "more conversion. <br/><br/>\n",
    "\n",
    "> Also looking at an interaction between page and country, there is no significant<br/>\n",
    "effects on conversion, either.<br/><br/>\n",
    "\n",
    "> For reasons above, I would suggest that it is not worth spending time and money to<br/>\n",
    "create and launch new page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
